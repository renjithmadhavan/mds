---
title: "week1_caravan_insurance_cx_profiling_r"
author: "Renjith Madhavan"
date: "1/30/2017"
output: html_document
---

## Introduction

Customer profiling for target marketing is an important area for potential application for data mining techniques. In this analysis we derive a typical profile of customers holding Caravan Insurance Policy. Such a profile would help identify customers with a similar profile who do not have caravan policies to both existing nonholders of caravan policies or new customers with similar profiles.

```{r}
library(sqldf)
#setwd("/tmp/working/kaggle/rstats/mds564")
dataset1 <- read.csv("ticdata2000.txt", sep = "\t", header = FALSE)
test <- read.csv("ticeval2000.txt", sep = "\t", header = FALSE)
actuals <- read.csv("tictgts2000.txt", sep = "\t", header = FALSE)
summary(dataset1)
str(dataset1)
d1 <- cor(dataset1[1:85],dataset1[86], method="spearman")

```



An initial review of the data revealed that for the religion parameters those customers who are Roman Catholic are further subdivided into 10 different levels with a range of percentage values (see Table Main Table and Sub Table L3 in Appendix A highlighted in grey). Despite various attempts to get more information about what such percentage value actually represents for a parameter that normally would have a simple binary value—that is, either someone is a Roman Catholic or not—we were unable to come up with a credible explanation. Given this lack of clarity, it was decided to exclude all four religion-related parameters (i.e., MGODRK—Roman Catholic; MGODPR—Protestant; MGODOV—Other religion; MGODGE—No religion) from further analysis presented here.
The correlations between customers’ religion and holding of Caravan Insurance is also not very significant. Hence, on the basis of this all four religion parameters have been excluded from further analysis presented here. 


```{r}
cname <- c('mostype', 'maanthui', 'mgemomv', 'mgemleef', 'moshoofd', 'mgodrk', 'mgodpr', 'mgodov', 'mgodge', 'mrelge', 'mrelsa', 'mrelov', 'mfalleen', 'mfgekind', 'mfwekind', 'moplhoog', 'moplmidd', 'mopllaag', 'mberhoog', 'mberzelf', 'mberboer', 'mbermidd', 'mberarbg', 'mberarbo', 'mska', 'mskb1', 'mskb2', 'mskc', 'mskd', 'mhhuur', 'mhkoop', 'maut1', 'maut2', 'maut0', 'mzfonds', 'mzpart', 'minkm30', 'mink3045', 'mink4575', 'mink7512', 'mink123m', 'minkgem', 'mkoopkla', 'pwapart', 'pwabedr', 'pwaland', 'ppersaut', 'pbesaut', 'pmotsco', 'pvraaut', 'paanhang', 'ptractor', 'pwerkt', 'pbrom', 'pleven', 'ppersong', 'pgezong', 'pwaoreg', 'pbrand', 'pzeilpl', 'pplezier', 'pfiets', 'pinboed', 'pbystand', 'awapart', 'awabedr', 'awaland', 'apersaut', 'abesaut', 'amotsco', 'avraaut', 'aaanhang', 'atractor', 'awerkt', 'abrom', 'aleven', 'apersong', 'agezong', 'awaoreg', 'abrand', 'azeilpl', 'aplezier', 'afiets', 'ainboed', 'abystand', 'caravan')

colnames(dataset1) <- cname
colnames(test) <- cname[1:85]
head(dataset1)
dataset2 <- dataset1[-c(6,7,8,9)]
test <- test[-c(6,7,8,9)]
dim(dataset2)
dim(test)
# sapply(test,function(x)any(is.na(x)))
```

The remaining 4 categorical variables are :
    mostype(41), mgemleef(6), moshoofd(10), pwapart(10) 
    
    
```{r}
sqldf("select mostype, mgemleef, moshoofd, pwapart from dataset1 limit 10")

```
    

```{r}
#dataset2 <- dataset1
### process categorical variable 1 - mostype
mostype_list <- sort(unique(dataset2$mostype))
for (i in mostype_list){
  dataset2[paste("mostype_", i, sep="")] <- ifelse(dataset2$mostype==i, 1, 0)
}
dataset2$mostype <- NULL
print(length(colnames(dataset2)))
#sqldf("select mostype_1, mostype_2, mostype_3 from dataset2 limit 10 ")

### process categorical variable 2 - mgemleef
mgemleef_list <- sort(unique(dataset2$mgemleef))
for (i in mgemleef_list){
  dataset2[paste("mgemleef_", i, sep="")] <- ifelse(dataset2$mgemleef==i, 1, 0)
}
dataset2$mgemleef <- NULL
print(length(colnames(dataset2)))
#sqldf("select mgemleef_1, mgemleef_2, mgemleef_3 from dataset2 limit 10 ")
colnames(dataset2)

### process categorical variable 3 - moshoofd
moshoofd_list <- sort(unique(dataset2$moshoofd))
for (i in moshoofd_list){
  dataset2[paste("moshoofd_", i, sep="")] <- ifelse(dataset2$moshoofd==i, 1, 0)
}
dataset2$moshoofd <- NULL
print(length(colnames(dataset2)))
#sqldf("select moshoofd_1, moshoofd_2, moshoofd_3 from dataset2 limit 10 ")
colnames(dataset2)

### process categorical variable 4 - pwapart
pwapart_list <- sort(unique(dataset2$pwapart))
for (i in pwapart_list){
  dataset2[paste("pwapart_", i, sep="")] <- ifelse(dataset2$pwapart==i, 1, 0)
}
dataset2$pwapart <- NULL
print(length(colnames(dataset2)))
#sqldf("select pwapart_1, pwapart_2, pwapart_3 from dataset2 limit 10 ")
colnames(dataset2)

# Create multiple column format from MOSTYPE column
# mostype_matrix <- model.matrix(~MOSTYPE, dataset3)
# rm(dataset3)
dataset2$pwapart_4 <- 0
dataset2$pwapart_5 <- 0
dataset2$pwapart_6 <- 0

dim(dataset2)



### processing test data set
### process categorical variable 1 - mostype
for (i in mostype_list){
  test[paste("mostype_", i, sep="")] <- ifelse(test$mostype==i, 1, 0)
}
test$mostype <- NULL

### process categorical variable 2 - mgemleef
for (i in mgemleef_list){
  test[paste("mgemleef_", i, sep="")] <- ifelse(test$mgemleef==i, 1, 0)
}
test$mgemleef <- NULL

### process categorical variable 3 - moshoofd
for (i in moshoofd_list){
  test[paste("moshoofd_", i, sep="")] <- ifelse(test$moshoofd==i, 1, 0)
}
test$moshoofd <- NULL

### process categorical variable 4 - pwapart
for (i in pwapart_list){
  test[paste("pwapart_", i, sep="")] <- ifelse(test$pwapart==i, 1, 0)
}
test$pwapart <- NULL

test$pwapart_4 <- 0
test$pwapart_5 <- 0
test$pwapart_6 <- 0

dim(test)
```


## Variable correlation and logistic regression analysis

```{r}

# install.packages("Hmisc")
library(Hmisc)
describe(dataset2)

```

Step 5


To see if there is any strong relationship between customer parameters and caravan.
The results did not elicit any strong link between Caravan Insurance holding and any other specific variable as can be seen from the plot below. Though the variables in this list are of some interest, the correlation between each pair is unlikely to be statistically significant. Overall, the results also confirmed the relatively low number of Caravan Insurance Policy holders in the database 

```{r}
prop1 <- prop.table(table(dataset1$mostype, dataset1$caravan), 1)
barplot(prop1[,2], xlab = "Customer Sub Type", ylab = "Proportion Of Caravan")
library(gmodels)
CrossTable(dataset2$caravan)
## The dataset is heavily unbalanced
```



```{r}
library(caret)
colnames(dataset2)
model <- glm(caravan ~ ., data=dataset2, na.action = na.exclude)
summary(model)
##  varImp(model)
# Variable importance plot is not working for some reason




```


## RP Model


```{r}
summary(dataset2)
#find out if there is any NA's
sapply(dataset2,function(x)any(is.na(x)))
# so there is no NA in any column

```

```{r}
###  Continuing with the RP model analysis
library(rpart)
tree_model <- rpart(caravan ~ ., method = "class", data = dataset2, control = rpart.control(cp = 0.001))
summary(tree_model)
plot(tree_model, uniform = TRUE)
text(tree_model)
```


```{r}
### I am trying to prune the tree above
plotcp(tree_model)
printcp(tree_model)

```

```{r}
## ## some cleanup
## rm(cname)
## rm(i)
## rm(mgemleef_list)
## rm(moshoofd_list)
## rm(mostype_list)
## rm(pwapart_list)
## rm(dataset1)

```


```{r}

## We have a really unablanced training data set.
## So I am adjusting prior probabilities to get around this
library(rpart)
library(rpart.plot)
library(caret)
tree_model_prior <- rpart(caravan ~ ., method = "class", data = dataset2, parms = list(prior=c(0.8, 0.2)), control = rpart.control(cp = 0.001))
summary(tree_model_prior)
plot(tree_model_prior, uniform = TRUE)
text(tree_model_prior)
plotcp(tree_model_prior)
printcp(tree_model_prior)
index <- which.min(tree_model_prior$cptable[ , "xerror"])
tree_min <- tree_model_prior$cptable[index, "CP"]
pruned_tree <- prune(tree_model_prior, cp = tree_min)
prp(pruned_tree)
summary(pruned_tree)
print(as.data.frame(pruned_tree$variable.importance))
barplot(pruned_tree$variable.importance)

labels <- names(pruned_tree$variable.importance)
mp <- barplot(pruned_tree$variable.importance, axes = TRUE, axisnames = FALSE)
text(mp, par("usr")[3], labels = labels, srt = 90, adj = c(1.1,.5), xpd = TRUE, cex=.9)
#axis(2)

```

From above pruned tree I checked the variable importance and below is in order.

1. PPERSAUT Contribution car policies
2. APERSAUT Number of car policies
3. PBRAND Contribution fire policies
4. ABRAND Number of fire policies
5. MOPLLAAG Lower level education
6. AWAPART Number of private third party insurance 1 - 12
. APLEZIER Number of boat policies
. PPLEZIER Contribution boat policies
. MOPLHOOG High level education
. MSKC Social class C
. MOPLMIDD Medium level education
. MSKA Social class A
. MBERHOOG High status
. MINKGEM Average income
. MHHUUR Rented house
. MINKM30 Income < 30.000
. MRELGE Married
. MFALLEEN Singles
. ATRACTOR Number of tractor policies
. PTRACTOR Contribution tractor policies
. PBYSTAND Contribution social security insurance policies
. MRELOV Other relation
. MINK4575 Income 45-75.000
. MHKOOP Home owners


```{r}

predict_tree_prior <- predict(pruned_tree, newdata = test, type = "class")
# the actual values are stored in vector actuals

# constructing confusion matix
actuals <- unlist(actuals)
actuals <- as.factor(actuals)
conf_predict_tree_prior <- table(actuals, predict_tree_prior)
print(conf_predict_tree_prior)

#calculating accuracy 

accuracy_tree_prior <- sum(diag(conf_predict_tree_prior)) / nrow(test)
print(accuracy_tree_prior)

```

Plotting ROC curves

```{r}
library(pROC)


## prepare the objects for ROC
# roc arguments need to be converted to numeric
roc_tree_prior <- roc(as.numeric(actuals), as.numeric(predict_tree_prior))
auc_1 <- auc(roc_tree_prior)
plot(roc_tree_prior)
print(auc(roc_tree_prior))

# print confusion matrix details using caret
print(confusionMatrix(as.numeric(actuals), as.numeric(predict_tree_prior)))

```


### Bagging Ensemble

Briefly, it works by splitting the data into multiple (training) data sets to which a class of learning or optimizing methods—that is decision trees and neural networks—is applied. The method is training multiple (k) models on different sets and then averaging the predictions of each model, hence bagging. The goal is to develop a model that optimizes the accuracy of one model. The rationale is that averaging of misclassification errors on different data splits gives a better estimate of the predictive ability of a learning method. 


```{r}
library(ipred)
cust.ip <- bagging(caravan ~ ., data=dataset2, coob=TRUE)
## cust.ip.prob <- predict(cust.ip, type="prob", newdata = test)
## using class type for class prediction
#cust.ip.c <- predict(cust.ip, type="prob", newdata = test)
## I had to change the target varaible to factor to get this working for classification

class(dataset2$caravan)
dataset2$caravan <- as.factor(dataset2$caravan)

cust.ip.cl <- predict(cust.ip, type="class", newdata = test)
head(cust.ip.cl)
# str(dataset2)
## sapply(test,function(x)any(!is.numeric(x)))

conf_bagging <- table(actuals, cust.ip.cl)
print(conf_bagging)

#calculating accuracy 

accuracy_bagging <- sum(diag(conf_bagging)) / nrow(test)
print(accuracy_bagging)

roc_bagging <- roc(as.numeric(actuals), as.numeric(cust.ip.cl))
auc_2 <- auc(roc_bagging)
plot(roc_bagging)
print(auc_2)

# print confusion matrix details using caret
print(confusionMatrix(as.numeric(actuals), as.numeric(cust.ip.cl)))
t1 <- varImp(cust.ip)
dim(t1)
t1$imp1 <- rownames(t1)
t2 <- sqldf("select imp1, Overall from t1 order by 2 desc limit 15")
t2
str(t2)
plot(as.factor(t2$imp1), t2$Overall)
```


### Support Vector Machine

Package e1071 can be used to implement svm

```{r}
library(e1071)
## below code is from text book

cust.svm <- svm(caravan ~ ., data=dataset2, method="C-classification", kernel="radial", cost=10, gamma=0.1,
                cross=0, fitted=TRUE, probability=TRUE)
summary(cust.svm)
cust.svm.predict <- predict(cust.svm, newdata=test)

## confusion matrix
conf_svm <- table(actuals, cust.svm.predict)
print(conf_svm)

#calculating accuracy 

accuracy_svm <- sum(diag(conf_svm)) / nrow(test)
print(accuracy_svm)

roc_svm <- roc(as.numeric(actuals), as.numeric(cust.svm.predict))
auc_3 <- auc(roc_svm)
plot(roc_svm)
print(auc_3)

# print confusion matrix details using caret
print(confusionMatrix(as.numeric(actuals), as.numeric(cust.svm.predict)))

```

Tune svm to find the cost and gamma values.

```{r}
# dataset3 <- dataset2
# dataset3$caravan <- NULL
# svm_tune <- tune(svm, train.x=dataset3, train.y=dataset2$caravan, 
#               kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
# 
# print(svm_tune)

```



### LR Method


```{r}
cust.logit <- glm(caravan ~ ., data=dataset2, family=binomial(link="logit"))
summary(cust.logit)
cust.var.imp <- varImp(cust.logit, useModel=glm)
head(cust.var.imp)
```


```{r}
cust.logit.pred <- predict(cust.logit, newdata=test, type="response")
head(cust.logit.pred)
```



Another try ..........


```{r}
t1 <- pruned_tree$variable.importance
t2 <- names(t1)
y <- "caravan"
x <- paste(t2, collapse=" + ")
fmla <- paste(y, paste(x, collapse="+"), sep=" ~ ")
dataset2$caravan <- as.factor(dataset2$caravan)
fmla
cust_logit_2 <- glm(fmla, data=dataset2, family=binomial(link = "logit"))
summary(cust_logit_2)
cust_logit_2_pred <- predict(cust_logit_2, newdata=test, type = "response")
head(cust_logit_2_pred)
### its giving me probabilties instead of class predictions.SO
## I will use cut-off manually

summary(cust_logit_2_pred)
cust_logit_cutoff <- ifelse(cust_logit_2_pred > 0.2, 1, 0)
head(cust_logit_cutoff)
## confusion matrix
conf_logit <- table(actuals, cust_logit_cutoff)
print(conf_logit)

#calculating accuracy 

accuracy_logit <- sum(diag(conf_logit)) / nrow(test)
print(accuracy_logit)

roc_logit <- roc(as.numeric(actuals), as.numeric(cust_logit_cutoff))
auc_4 <- auc(roc_logit)
plot(roc_logit)
print(auc_4)

# print confusion matrix details using caret
## note the use of argument, always specify "positive" to avoid confusion
print(confusionMatrix(as.factor(actuals), as.factor(cust_logit_cutoff), positive = "1"))
print(confusionMatrix(as.factor(actuals), as.factor(cust_logit_cutoff)))
```

### Plot the ROC Curve


```{r}
roc_tree_prior_roc <- prediction(as.numeric(predict_tree_prior), as.numeric(actuals))
roc_rp <- performance(roc_tree_prior_roc, "tpr", "fpr")

roc_bagging_roc <- prediction(as.numeric(cust.ip.cl), as.numeric(actuals))
roc_be <- performance(roc_bagging_roc, "tpr", "fpr")

roc_svm_roc <- prediction(as.numeric(cust.svm.predict), as.numeric(actuals))
roc_svm <- performance(roc_svm_roc, "tpr", "fpr")

roc_logit_roc <- prediction(as.numeric(cust_logit_cutoff), as.numeric(actuals))
roc_logit <- performance(roc_logit_roc, "tpr", "fpr")

# draw the ROC-curves in a single plot

# plot(roc_rp)
# lines(roc_be, col = "blue")
# lines(roc_svm, col = "red")
# lines(roc_logit, col = "green")


#ppi <- 300
#png(filename = "Accuracy versus Cut-off curve without religion variables.png", width=6*ppi, height=6*ppi, res=ppi)
plot(roc_rp, col=2, main="Accuracy versus Cut-off curve without religion variables")
legend(0.5,0.5, c('rpart','bagging','svm', 'logistic'), 2:5)
plot(roc_be, col=3, add=TRUE)
plot(roc_svm, col=4, add=TRUE)
plot(roc_logit, col=5, add=TRUE)
#dev.off()


library(ROCR)
cust.rp.prob.pred <- prediction(as.numeric(predict_tree_prior), as.numeric(actuals))
customer.rp.perf <- performance(cust.rp.prob.pred, "tpr", "fpr")
plot(customer.rp.perf, main="ROC Curve using recursive partitioning", colrize=T)
```















